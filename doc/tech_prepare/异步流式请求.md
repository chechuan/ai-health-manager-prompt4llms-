```python
import asyncio

from openai import AsyncOpenAI

client = AsyncOpenAI(
    base_url="http://10.228.67.99:26928/v1",
    # api_key="EMPTY",
)


async def arequest():
    response = await client.chat.completions.create(
        model="Qwen1.5-32B-Chat",
        messages=[{"role": "user", "content": "你是谁"}],
        stream=True,
    )
    async for chunk in response:
        content = chunk.choices[0].delta.content
        if content:
            print(content, end="", flush=True)


def main():
    asyncio.run(arequest())


if __name__ == "__main__":
    main()
```

# Explaining the code

在上面的代码中，我们使用了 `AsyncOpenAI` 类来异步地请求 OpenAI 的 API。我们通过 `chat.completions.create` 方法来请求模型的推理结果，并设置 `stream=True` 来启用流式请求。

在 `arequest` 函数中，我们使用 `async for` 循环来异步地迭代 `response` 对象，并从 `choices` 字段中获取推理结果。我们只打印 `content` 字段，并在 `end` 参数中设置 `""` 来避免换行。

在 `main` 函数中，我们调用 `arequest` 函数，并使用 `asyncio.run` 方法来运行异步代码。
