# -*- encoding: utf-8 -*-
'''
@Time    :   2024-01-25 01:05:35
@desc    :   simple chatbot
@Author  :   ticoAg
@Contact :   1627635056@qq.com
'''

import os
import time

import streamlit as st
from loguru import logger
from openai import OpenAI

client = OpenAI()

class Args:
    ...
args = Args()
def prepare_parameters():
    """Initialize the parameters for the llm"""
    global args
    args.max_tokens = st.sidebar.slider("Max tokens", min_value=1, max_value=32000, value=4096, step=1)
    args.temperature = st.sidebar.slider("Temperature", min_value=0.0, max_value=2.0, value=0.7, step=0.1)
    args.top_p = st.sidebar.slider("Top p", min_value=0.0, max_value=1.0, value=0.8, step=0.1)
    # args.top_k = st.sidebar.slider("Top k", min_value=-1, max_value=100, value=-1, step=1)
    args.n = st.sidebar.slider("N", min_value=1, max_value=50, value=1, step=1)
    args.stop = st.sidebar.text_input("Stop words(split with `,`)", value="")
    args.presence_penalty = st.sidebar.slider("Presence penalty", min_value=0.0, max_value=2.0, value=0.0, step=0.1)
    args.frequency_penalty = st.sidebar.slider("Frequency penalty", min_value=0.0, max_value=2.0, value=0.0, step=0.1)

with st.sidebar:
    client.base_url = st.text_input("api base", key="openai_api_base", value=os.environ.get("OPENAI_API_BASE", ""))
    api_key = st.text_input("api key", key="openai_api_key", value=None)
    client.api_key = api_key if api_key else os.environ.get("OPENAI_API_KEY", "")
    
    model_list = [i.id for i in client.models.list().data]
    args.model = st.selectbox("Choose your model", model_list,index=1)

    system_prompt = st.text_area(
        "system prompt", 
"""è¯·ä½ æ¨¡æ‹ŸåŒ»ç”Ÿé—®è¯Šçš„è¿‡ç¨‹ï¼Œé€æ­¥åˆ†æç”¨æˆ·çš„ç—…æƒ…ï¼Œç»™å‡ºåˆæ­¥è¯Šæ–­ï¼Œè¯·éµå¾ªä¸€ä¸‹æµç¨‹:
1. æ˜ç¡®æ‚£è€…ä¸»è¯‰ä¿¡æ¯
2. é€æ­¥è¯¢é—®æ‚£è€…æŒç»­æ—¶é—´ã€å‘ç”Ÿæ—¶æœºã€è¯±å› æˆ–ç—‡çŠ¶å‘ç”Ÿéƒ¨ä½ç­‰ä¿¡æ¯ï¼Œæ¯æ¬¡åªé—®ä¸€ä¸ªé—®é¢˜
3. æ˜ç¡®å¿…è¦çš„æ‚£è€…ä¿¡æ¯åï¼Œæ¨æ–­ç”¨æˆ·å¯èƒ½æ‚£æœ‰çš„ç–¾ç—…ï¼Œé€æ­¥è¯¢é—®æ‚£è€…ç–¾ç—…åˆè¯Šã€é‰´åˆ«è¯Šæ–­ã€ç¡®è¯Šéœ€è¦çš„å…¶ä»–ä¿¡æ¯, å¦‚å®¶æ—å²ã€æ—¢å¾€å²ã€æ£€æŸ¥ç»“æœç­‰ä¿¡æ¯
4. ç»è¿‡å¤šè½®é—®è¯Šåç»™å‡ºåˆæ­¥è¯Šæ–­ç»“æœï¼Œåˆ—å‡ºå¯èƒ½æ€§æœ€é«˜çš„å‡ ç§ç–¾ç—…å¹¶è§£é‡ŠåŸå› """,
    height=200
    )
    # "[Get an OpenAI API key](https://platform.openai.com/account/api-keys)"
    "[View the source code](https://github.com/streamlit/llm-examples/blob/main/Chatbot.py)"
    # "[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/streamlit/llm-examples?quickstart=1)"

prepare_parameters()
st.title("ğŸ’¬ Chatbot")
st.caption("ğŸš€ A streamlit chatbot powered by OpenSource LLM")
if "messages" not in st.session_state:
    st.session_state['messages'] = []
    if system_prompt:
        st.session_state.messages.append({"role": "system", "content": system_prompt})

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("Your message"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.spinner("AI is thinking..."):
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            for response in client.chat.completions.create(**args.__dict__, 
                                                            messages=st.session_state.messages, 
                                                            stream=True):
                if not response.choices[0].delta.content:
                    continue
                full_response += response.choices[0].delta.content
                message_placeholder.markdown(full_response + "â–Œ")
                time.sleep(0.03)
            message_placeholder.markdown(full_response)
        st.session_state.messages.append({"role": "assistant", "content": full_response})
        logger.info(f"User: {prompt}\nAssistant: {full_response}\nHistory: {st.session_state.messages}")

# pip install openai --upgrade
# streamlit run Chatbot.py --server.port